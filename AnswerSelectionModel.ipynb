{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import basic_model\n",
    "import random\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import ujson as json\n",
    "from torch.autograd import Variable\n",
    "import util\n",
    "import args\n",
    "import pprint\n",
    "import Answer_Selection_Model\n",
    "\n",
    "args = args.get_setup_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific param for this model\n",
    "args.question_len = 20\n",
    "args.answer_len = 200\n",
    "args.embedding_dim = 512\n",
    "args.hidden_dim = 512\n",
    "args.margin = 0.05\n",
    "args.mode = 'test'\n",
    "args.resume = 1\n",
    "args.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_path': '/home/mouadh/Desktop/insuranceQA/V2/vocabulary',\n",
       " 'label_path': '/home/mouadh/Desktop/insuranceQA/V2/InsuranceQA.label2answer.token.encoded',\n",
       " 'train_path': '/home/mouadh/Desktop/insuranceQA/V2/InsuranceQA.question.anslabel.token.500.pool.solr.train.encoded',\n",
       " 'test_path': '/home/mouadh/Desktop/insuranceQA/V2/InsuranceQA.question.anslabel.token.500.pool.solr.test.encoded',\n",
       " 'glove_path': '/home/mouadh/Desktop/insuranceQA/glove.840B.300d/glove.840B.300d.txt',\n",
       " 'glove_dim': 300,\n",
       " 'glove_num_vecs': 2196017,\n",
       " 'hidden_size': 100,\n",
       " 'word_emb_file': '/home/mouadh/Desktop/insuranceQA/glove.840B.300d/word_embedding',\n",
       " 'word2idx_file': '/home/mouadh/Desktop/insuranceQA/glove.840B.300d/word2idx',\n",
       " 'seed': 0,\n",
       " 'create_matrix_embedding': True,\n",
       " 'learning_rate': 0.01,\n",
       " 'num_epochs': 30,\n",
       " 'drop_prob': 0.2,\n",
       " 'margin': 0.05,\n",
       " 'batch_size': 1,\n",
       " 'use_glove': False,\n",
       " 'embd_size': 200,\n",
       " 'max_sent_len': 200,\n",
       " 'question_len': 20,\n",
       " 'answer_len': 200,\n",
       " 'embedding_dim': 512,\n",
       " 'hidden_dim': 512,\n",
       " 'mode': 'test',\n",
       " 'resume': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 68581\n"
     ]
    }
   ],
   "source": [
    "# Load answers labels and answer label with text\n",
    "id2w, l2a, l2at = util.load_vocabulary(args.vocab_path, args.label_path)\n",
    "\n",
    "# Create word to index vocabulary\n",
    "w2i = {w: i for i, w in enumerate(id2w.values(), 1)}\n",
    "# Add pad to the vocabulary\n",
    "PAD = '<PAD>'\n",
    "w2i[PAD] = 0\n",
    "\n",
    "vocab_size = len(w2i)\n",
    "args.vocab_size = vocab_size\n",
    "print('vocab_size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = util.load_data_train(args.train_path, id2w, l2at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = util.load_data_train(args.test_path, id2w, l2at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_glove:\n",
    "    if not args.create_matrix_embedding:\n",
    "        # Create word embedding and word2idx for glove\n",
    "        print(\"Creating word embedding\")\n",
    "        word_emb_mat, word2idx_dict = util.get_embedding('word', emb_file=args.glove_path,\n",
    "                                        vec_size=args.glove_dim, num_vectors=args.glove_num_vecs)\n",
    "        util.save(args.word_emb_file, word_emb_mat, message=\"word embedding\")\n",
    "        util.save(args.word2idx_file, word2idx_dict, message=\"word dictionary\")\n",
    "    else:\n",
    "        # Get embeddings\n",
    "        print('Loading word vectors embeddings...')\n",
    "        word_vectors = util.torch_from_json(args.word_emb_file)\n",
    "        print(\"Loading word to index dictionary\")\n",
    "        word2idx_dict = json.load(open(args.word2idx_file))\n",
    "else:\n",
    "    word2idx_dict = w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'Disability', 'Insurance', 'Required', 'By', 'Law', '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50370"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_dict['?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[66164, 54421, 29876, 56902, 59631, 57715, 50370,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.make_vector([train[0][0]], w2i, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, pos, negs = train[0][0], train[0][1], train[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_q = util.make_vector([q], word2idx_dict, args.question_len)\n",
    "vec_pos = util.make_vector([pos], word2idx_dict,args.answer_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_neg = util.make_vector([negs[1]], word2idx_dict, args.answer_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ = torch.LongTensor(vec_q)\n",
    "ga_ = torch.LongTensor(vec_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_ = torch.LongTensor(vec_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "import torch\n",
    "#import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class AnswerSelection(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(AnswerSelection, self).__init__()\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.embedding_dim = args.embedding_dim\n",
    "        self.question_len = args.question_len\n",
    "        self.answer_len = args.answer_len\n",
    "        self.batch_size = args.batch_size\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim // 2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.cnns = nn.ModuleList([nn.Conv1d(self.hidden_dim, 500, filter_size, stride=1, padding=filter_size-(i+1)) for i, filter_size in enumerate([1,3])])\n",
    "        self.question_maxpool = nn.MaxPool1d(self.question_len, stride=1)\n",
    "        self.answer_maxpool = nn.MaxPool1d(self.answer_len, stride=1)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.init_weights()\n",
    "        self.hiddenq = self.init_hidden(self.batch_size)\n",
    "        self.hiddena = self.init_hidden(self.batch_size)\n",
    "\n",
    "    def init_hidden(self, batch_len):\n",
    "        return (Variable(torch.randn(2, batch_len, self.hidden_dim // 2)),\n",
    "                Variable(torch.randn(2, batch_len, self.hidden_dim // 2)))\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.word_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, question, answer):\n",
    "        question_embedding = self.word_embeddings(question)\n",
    "        answer_embedding = self.word_embeddings(answer)\n",
    "        q_lstm, self.hiddenq = self.lstm(question_embedding, self.hiddenq)\n",
    "        a_lstm, self.hiddena = self.lstm(answer_embedding, self.hiddena)\n",
    "        q_lstm = q_lstm.contiguous()\n",
    "        a_lstm = a_lstm.contiguous()\n",
    "        q_lstm = question_embedding\n",
    "        a_lstm = answer_embedding\n",
    "        print(q_lstm.size())\n",
    "        q_lstm = q_lstm.view(-1,self.hidden_dim, self.question_len)\n",
    "        a_lstm = a_lstm.view(-1,self.hidden_dim, self.answer_len)\n",
    "\n",
    "        question_pool = []\n",
    "        answer_pool = []\n",
    "        for cnn in self.cnns:\n",
    "            question_conv = cnn(q_lstm)\n",
    "            answer_conv = cnn(a_lstm)\n",
    "            question_max_pool = self.question_maxpool(question_conv)\n",
    "            answer_max_pool = self.answer_maxpool(answer_conv)\n",
    "            question_activation = F.tanh(torch.squeeze(question_max_pool))\n",
    "            answer_activation = F.tanh(torch.squeeze(answer_max_pool))\n",
    "            question_pool.append(question_activation)\n",
    "            answer_pool.append(answer_activation)\n",
    "            \n",
    "        question_output = torch.cat(question_pool, dim = 0)\n",
    "        answer_output = torch.cat(answer_pool, dim = 0)\n",
    "        #print((question_output != torch.cat(question_pool, dim = -1)).sum())\n",
    "        question_output = self.dropout(question_output)\n",
    "        answer_output = self.dropout(answer_output)\n",
    "        \n",
    "        similarity = F.cosine_similarity(question_output, answer_output, dim = -1)\n",
    "\n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnswerSelection(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8401, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(vec_q, vec_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8548, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(vec_q, vec_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "        batch_size = args.batch_size\n",
    "        epochs = args.epochs\n",
    "        training_set = load('train')\n",
    "\n",
    "        questions = list()\n",
    "        good_answers = list()\n",
    "        for i, q in enumerate(training_set):\n",
    "            questions += [q['question']] * len(q['answers'])\n",
    "            good_answers += [self.all_answers[j] for j in q['answers']]\n",
    "\n",
    "        questions = torch.LongTensor(self.pad_question(questions))\n",
    "        good_answers = torch.LongTensor(self.pad_answer(good_answers))\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.conf['learning_rate'])\n",
    "\n",
    "        for i in xrange(epochs):\n",
    "            bad_answers = torch.LongTensor(self.pad_answer(random.sample(self.all_answers.values(), len(good_answers))))\n",
    "            train_loader = data.DataLoader(dataset=torch.cat([questions,good_answers,bad_answers],dim=1), batch_size=batch_size)\n",
    "\t    avg_loss = []\n",
    "\t    avg_acc = []\n",
    "\t    self.model.train()\n",
    "            for step, train in enumerate(train_loader):\n",
    "                batch_question = autograd.Variable(train[:,:self.conf['question_len']]).cuda()\n",
    "                batch_good_answer = autograd.Variable(train[:,self.conf['question_len']:self.conf['question_len']+self.conf['answer_len']]).cuda()\n",
    "                batch_bad_answer = autograd.Variable(train[:,self.conf['question_len']+self.conf['answer_len']:]).cuda()\n",
    "                optimizer.zero_grad()\n",
    "\t\tself.model.hiddenq = self.model.init_hidden(len(train))\n",
    "\t\tself.model.hiddena = self.model.init_hidden(len(train))\n",
    "\t\tloss, acc = self.model.fit(batch_question, batch_good_answer, batch_bad_answer)\n",
    "\t\tavg_loss.append(loss.data[0])\n",
    "\t\tavg_acc.append(acc)\n",
    "                loss.backward()\n",
    "\t        torch.nn.utils.clip_grad_norm(self.model.parameters(), 0.25)\n",
    "                optimizer.step()\n",
    "\n",
    "\t    print \"Epoch: {0} Epoch Average loss: {1} Accuracy {2}\".format(str(i), str(np.mean(avg_loss)), str(np.mean(avg_acc)))\n",
    "            torch.save(self.model.state_dict(), \"saved_model/answer_selection_model_cnnlstm\")\n",
    "\t    if i % 50 == 0 and i > 0:\n",
    "\t\tself.validate(validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
